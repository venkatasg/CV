%%%%%%%%%% CONFERENCE PAPERS %%%%%%%%%%%

@inproceedings{govindarajan-etal-2025-diversity,
    title = "\href{https://arxiv.org/abs/2505.17390}{Measuring Lexical Diversity of Synthetic Data Generated through Fine-Grained Persona Prompting}",
    author = "Kambhatla, Gauri  and
      Shaib, Chantal  and
      Govindarajan, Venkata S",
    author+an = {3=highlight},
    booktitle = "To appear in Findings of the Association for Computational Linguistics: EMNLP 2025",
    month = nov,
    year = "2025",
}

@inproceedings{paul-etal-2025-recommendations,
    title = "\href{https://ceur-ws.org/Vol-4045/}{Using Language Models for Music Recommendations with Natural-Language Profiles}",
    author = "Gagliano, Paul  and
      Homan, Griffin  and
      Turnbull, Douglas and
      Govindarajan, Venkata S",
    author+an = {4=highlight},
    booktitle = "Proceedings of the 3rd Music Recommender Systems Workshop (MuRS 2025)",
    month = sep,
    year = "2025",
    address = "Prague",
    publisher = "19th ACM Conference on Recommender Systems (RecSys 2025)"
}

@inproceedings{govindarajan-etal-2024-mean,
    title = "\href{https://aclanthology.org/2024.findings-emnlp.571}{Do *they* mean {`}us{'}? Interpreting Referring Expression variation under Intergroup Bias}",
    author = "Govindarajan, Venkata S  and
      Zang, Matianyu  and
      Mahowald, Kyle  and
      Beaver, David  and
      Li, Junyi Jessy",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    author+an = {1=highlight},
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.571",
    doi = "10.18653/v1/2024.findings-emnlp.571",
    pages = "9772--9785",
    abstract = "The variations between in-group and out-group speech (intergroup bias) are subtle and could underlie many social phenomena like stereotype perpetuation and implicit bias. In this paper, we model intergroup bias as a tagging task on English sports comments from forums dedicated to fandom for NFL teams. We curate a dataset of over 6 million game-time comments from opposing perspectives (the teams in the game), each comment grounded in a non-linguistic description of the events that precipitated these comments (live win probabilities for each team). Expert and crowd annotations justify modeling the bias through tagging of implicit and explicit referring expressions and reveal the rich, contextual understanding of language and the world required for this task. For large-scale analysis of intergroup variation, we use LLMs for automated tagging, and discover that LLMs occasionally perform better when prompted with linguistic descriptions of the win probability at the time of the comment, rather than numerical probability. Further, large-scale tagging of comments using LLMs uncovers linear variations in the form of referent across win probabilities that distinguish in-group and out-group utterances.",
}

@inproceedings{srinivasan-etal-2023-counterfactually,
    title = "\href{https://aclanthology.org/2023.conll-babylm.27}{Counterfactually Probing Language Identity in Multilingual Models}",
    author = "Srinivasan, Anirudh  and
      Govindarajan, Venkata S  and
      Mahowald, Kyle",
    author+an = {2=highlight},
    editor = "Ataman, Duygu",
    booktitle = "Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL)",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.mrl-1.3",
    pages = "24--36",
}

@inproceedings{govindarajan-etal-2023-lil,
    title = "\href{https://aclanthology.org/2023.conll-babylm.27}{Lil-Bevo: Explorations of Strategies for Training Language Models in More Humanlike Ways}",
    author = "Govindarajan, Venkata S  and
      Rodriguez, Juan Diego  and
      Bostrom, Kaj  and
      Mahowald, Kyle",
    editor = "Warstadt, Alex  and
      Mueller, Aaron  and
      Choshen, Leshem  and
      Wilcox, Ethan  and
      Zhuang, Chengxu  and
      Ciro, Juan  and
      Mosquera, Rafael  and
      Paranjabe, Bhargavi  and
      Williams, Adina  and
      Linzen, Tal  and
      Cotterell, Ryan",
    author+an = {1=highlight},
    booktitle = "Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.conll-babylm.27",
    pages = "280--288",
}

@inproceedings{govindarajan-etal-2023-counterfactual,
    title = "\href{https://aclanthology.org/2023.findings-acl.813}{Counterfactual Probing for the Influence of Affect and Specificity on Intergroup Bias}",
    author = "Govindarajan, Venkata S  and
      Beaver, David  and
      Mahowald, Kyle  and
      Li, Junyi Jessy",
    author+an = {1=highlight},
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "ACL",
    url = "https://aclanthology.org/2023.findings-acl.813",
    pages = "12853--12862",
    abstract = "While existing work on studying bias in NLP focues on negative or pejorative language use, Govindarajan et al. (2023) offer a revised framing of bias in terms of intergroup social context, and its effects on language behavior. In this paper, we investigate if two pragmatic features (specificity and affect) systematically vary in different intergroup contexts {---} thus connecting this new framing of bias to language output. Preliminary analysis finds modest correlations between specificity and affect of tweets with supervised intergroup relationship (IGR) labels. Counterfactual probing further reveals that while neural models finetuned for predicting IGR reliably use affect in classification, the model{'}s usage of specificity is inconclusive.",
    keywords={resume}
}

@inproceedings{govindarajan-etal-2023-people,
    title = "\href{https://aclanthology.org/2023.eacl-main.183}{How people talk about each other: Modeling Generalized Intergroup Bias and Emotion}",
    author = "Govindarajan, Venkata S  and
      Atwell, Katherine  and
      Sinno, Barea  and
      Alikhani, Malihe  and
      Beaver, David  and
      Li, Junyi Jessy",
    author+an = {1=highlight},
    booktitle = "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "ACL",
    url = "https://aclanthology.org/2023.eacl-main.183",
    pages = "2488--2498",
    abstract = "Current studies of bias in NLP rely mainly on identifying (unwanted or negative) bias towards a specific demographic group. While this has led to progress recognizing and mitigating negative bias, and having a clear notion of the targeted group is necessary, it is not always practical. In this work we extrapolate to a broader notion of bias, rooted in social science and psychology literature. We move towards predicting interpersonal group relationship (IGR) - modeling the relationship between the speaker and the target in an utterance - using fine-grained interpersonal emotions as an anchor. We build and release a dataset of English tweets by US Congress members annotated for interpersonal emotion - the first of its kind, and {`}found supervision{'} for IGR labels; our analyses show that subtle emotional signals are indicative of different biases. While humans can perform better than chance at identifying IGR given an utterance, we show that neural models perform much better; furthermore, a shared encoding between IGR and interpersonal perceived emotion enabled performance gains in both tasks.",
    keywords={resume}
}

@inproceedings{kovatchev-etal-2022-longhorns,
    title = {\href{https://aclanthology.org/2022.dadc-1.5}{longhorns at {DADC} 2022: How many linguists does it take to fool a Question Answering model? A systematic approach to adversarial attacks.}},
    author+an = {3=highlight},
    author = "Kovatchev, Venelin  and
      Chatterjee, Trina  and
      Govindarajan, Venkata S  and
      Chen, Jifan  and
      Choi, Eunsol  and
      Chronis, Gabriella  and
      Das, Anubrata  and
      Erk, Katrin  and
      Lease, Matthew  and
      Li, Junyi Jessy  and
      Wu, Yating  and
      Mahowald, Kyle",
    booktitle = {Proceedings of the First Workshop on Dynamic Adversarial Data Collection},
    month = jul,
    year = {2022},
    address = {Seattle, WA},
    publisher = {ACL},
    url = {https://aclanthology.org/2022.dadc-1.5},
    pages = {41--52},
    abstract = {Developing methods to adversarially challenge NLP systems is a promising avenue for improving both model performance and interpretability. Here, we describe the approach of the team {``}longhorns{''} on Task 1 of the The First Workshop on Dynamic Adversarial Data Collection (DADC), which asked teams to manually fool a model on an Extractive Question Answering task. Our team finished first (pending validation), with a model error rate of 62{\%}. We advocate for a systematic, linguistically informed approach to formulating adversarial questions, and we describe the results of our pilot experiments, as well as our official submission.},
}

@inproceedings{venkat2020advice,
    title = {\href{https://www.aclweb.org/anthology/2020.emnlp-main.427/}{Help! Need Advice on Identifying Advice}},
    author = "Govindarajan, Venkata S  and
      Chen, Benjamin  and
      Warholic, Rebecca  and
      Erk, Katrin  and
      Li, Junyi Jessy",
    author+an = {1=highlight},
    booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
    month = nov,
    year = {2020},
    address = {Online},
    publisher = {ACL},
    url = {https://aclanthology.org/2020.emnlp-main.427},
    doi = {10.18653/v1/2020.emnlp-main.427},
    pages = {5295--5306},
    abstract = {Humans use language to accomplish a wide variety of tasks - asking for and giving advice being one of them. In online advice forums, advice is mixed in with non-advice, like emotional support, and is sometimes stated explicitly, sometimes implicitly. Understanding the language of advice would equip systems with a better grasp of language pragmatics; practically, the ability to identify advice would drastically increase the efficiency of advice-seeking online, as well as advice-giving in natural language generation systems. We present a dataset in English from two Reddit advice forums - r/AskParents and r/needadvice - annotated for whether sentences in posts contain advice or not. Our analysis reveals rich linguistic phenomena in advice discourse. We present preliminary models showing that while pre-trained language models are able to capture advice better than rule-based systems, advice identification is challenging, and we identify directions for future research.},
    keywords = {resume}
}

@InProceedings{white2019universal,
  author    = {White, Aaron Steven  and  Stengel-Eskin, Elias  and  Vashishtha, Siddharth  and  Govindarajan, Venkata S  and  Reisinger, Dee Ann  and  Vieira, Tim  and  Sakaguchi, Keisuke  and  Zhang, Sheng  and  Ferraro, Francis  and  Rudinger, Rachel  and  Rawlins, Kyle  and  Van Durme, Benjamin},
  author+an = {4=highlight},
  title     = {\href{https://www.aclweb.org/anthology/2020.lrec-1.699}{The Universal Decompositional Semantics Dataset and Decomp Toolkit}},
  booktitle      = {Proceedings of The 12th Language Resources and Evaluation Conference (LREC)},
  month          = {May},
  year           = {2020},
  address        = {Marseille, France},
 publisher      = {European Language Resources Association},
  pages     = {5698--5707}
}


%%%%%%%%% JOURNAL PAPERS %%%%%%%

@article{genericity,
    author = {Govindarajan, Venkata S and Durme, Benjamin Van and White, Aaron Steven},
    author+an = {1=highlight},
    title = {\href{https://doi.org/10.1162/tacl_a_00285}{Decomposing Generalization: Models of Generic , Habitual, and Episodic Statements}},
    journal = {Transactions of the Association for Computational Linguistics (TACL)},
    volume = {7},
    number = {},
    pages = {501-517},
    year = {2019},
    abstract = { We present a novel semantic framework for modeling linguistic expressions of generalization— generic, habitual, and episodic statements—as combinations of simple, real-valued referential properties of predicates and their arguments. We use this framework to construct a dataset covering the entirety of the Universal Dependencies English Web Treebank. We use this dataset to probe the efficacy of type-level and token-level information—including hand-engineered features and static (GloVe) and contextual (ELMo) word embeddings—for predicting expressions of generalization. },
    keywords = {resume}
}


%%%%%%%%% TALKS %%%%%%%%%

@misc{hopsuds-talk,
    author    = {},
    title     = {Diving into LLMs like ChatGPT: How do they work?},
    howpublished      = {\href{https://www.limehollow.org/science-suds}{Hopshire's Science \& Suds} (Public outreach)},
    date = {2025-05},
    year={2025},
    location = {Ithaca, NY},
}

@misc{ithaca-talk,
    author    = {},
    title     = {Computational Linguistic Models of Social Identity},
    howpublished      = {Invited talk},
    date = {2024-02},
    year={2024},
    location = {Ithaca College},
}

@misc{georgetown-talk,
    author    = {},
    title     = {Computational Models of Social Meaning},
    howpublished      = {Invited talk},
    date = {2024-01},
    year={2024},
    location = {Georgetown University},
}

@misc{inter-talk,
    author    = {},
    title     = {\href{https://aclanthology.org/2023.eacl-main.183.mp4}{Modeling Generalized Intergroup Bias}},
    howpublished      = {Conference talk at EACL 2023},
    date = {2023-05},
}

@misc{advice-talk,
    author    = {},
    title     = {\href{https://slideslive.com/38939263/help-need-advice-on-identifying-advice}{Help! Need Advice on Identifying Advice}},
    howpublished      = {Conference talk at EMNLP 2020},
    date = {2020-11},
}

@misc{genericity-talk,
    author = {},
    title = {Decomposing Generalization},
    howpublished = {Conference talk at ACL 2020},
    date = {2020-07},
}
